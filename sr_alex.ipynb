{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sr_alex.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"g5RQsvi5KYBM","colab_type":"code","outputId":"82c713ac-67d9-420e-cf25-1f1b03e1c97d","executionInfo":{"status":"ok","timestamp":1561569383290,"user_tz":240,"elapsed":215,"user":{"displayName":"Alexandru Damian","photoUrl":"","userId":"02461557059013045939"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6udYoG1LKNS-","colab_type":"code","outputId":"c6d183da-3933-4cd3-cbea-2a1d9487d33f","executionInfo":{"status":"ok","timestamp":1561569383693,"user_tz":240,"elapsed":144,"user":{"displayName":"Alexandru Damian","photoUrl":"","userId":"02461557059013045939"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/gdrive/My\\ Drive/stylegan-refactor"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/stylegan-refactor\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"riPsduVROmGI","colab_type":"code","outputId":"ec4ca6d8-13fe-49a1-9d45-df46d99e8d78","executionInfo":{"status":"ok","timestamp":1561569389915,"user_tz":240,"elapsed":5786,"user":{"displayName":"Alexandru Damian","photoUrl":"","userId":"02461557059013045939"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["!pip install git+https://github.com/rcmalli/keras-vggface.git"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/rcmalli/keras-vggface.git\n","  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-nouc8q6g\n","  Running command git clone -q https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-nouc8q6g\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.5) (1.16.4)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.5) (1.3.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.5) (2.8.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.5) (4.3.0)\n","Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.5) (2.2.4)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.5) (1.12.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.5) (3.13)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->keras-vggface==0.5) (0.46)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.5) (1.0.8)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.5) (1.1.0)\n","Building wheels for collected packages: keras-vggface\n","  Building wheel for keras-vggface (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-f16rbpjj/wheels/36/07/46/06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n","Successfully built keras-vggface\n","Installing collected packages: keras-vggface\n","Successfully installed keras-vggface-0.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IJFNCSxRwFlK","colab_type":"code","outputId":"993c56cb-ef48-43ae-b2ad-857a67abf778","executionInfo":{"status":"ok","timestamp":1561572672474,"user_tz":240,"elapsed":170235,"user":{"displayName":"Alexandru Damian","photoUrl":"","userId":"02461557059013045939"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["%cd /content/gdrive/My\\ Drive/stylegan-refactor\n","!python encoder.py -i ./aligned_realpics/64/chicago2.png -n l2only --img_size 64 --layersF 1 5 --steps 700 --loss 1*L2+0.0075*REG+0.0075*CROSS --lr 0.1 --optimizer ADAM --mask_type SEGMENT"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/stylegan-refactor\n","Using TensorFlow backend.\n","using -n for output\n","Working on chicago2.png\n","Built mask from image\n","L2: 0.097/0.093 REG: 3.989/3.814 CROSS: 6.652/5.928, TOTAL: 0.177/0.166, BEST_IDX: 685, LR: 0.10000: 100% 700/700 [02:13<00:00,  5.87it/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9BbzGCqFkRF8","colab_type":"code","colab":{}},"source":["%cd /content/gdrive/My\\ Drive/stylegan-refactor\n","!cat layerloop.sh"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_AvYhQOPLdxg","colab_type":"code","colab":{}},"source":["%cd /content/gdrive/My\\ Drive/stylegan-refactor\n","!bash layerloop.sh"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"06fd11be-6290-4729-c499-1bae55874ff9","executionInfo":{"status":"ok","timestamp":1561325577373,"user_tz":240,"elapsed":2846,"user":{"displayName":"Alexandru Damian","photoUrl":"","userId":"02461557059013045939"}},"id":"L6ExQoZ1DyiB","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["from pathlib import Path\n","from keras.preprocessing import image\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import PIL.Image\n","from bicubic_downsample import Downsampler\n","\n","def load_image(im, img_size): \n","    img = image.load_img(im)\n","    img = np.expand_dims(img, 0)\n","    sess = tf.Session()\n","    D = Downsampler()\n","    with sess.as_default():\n","      img = tf.cast(img,dtype='float32')\n","      img = D.resize_bicubic(img, img_size)\n","      img = tf.saturate_cast(img,dtype='uint8')\n","      img = img.eval()\n","    return img[0]\n","  \n","SIZE=64;\n","  \n","for im_path in Path().glob(\"aligned_realpics/*.png\"):\n","  out_file = Path(\"aligned_realpics\")/str(SIZE)/im_path.name\n","  out_file.parent.mkdir(parents=True,exist_ok=True)\n","  if(out_file.is_file()):\n","    print(f\"Found {im_path.name}\")\n","  else:\n","    img = load_image(im_path,SIZE)\n","    img = PIL.Image.fromarray(img)\n","    img.save(out_file)\n","    print(f\"Saved {im_path.name}\")\n","  "],"execution_count":62,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Found chicago3.png\n","Found ObamaHR.png\n","Found chicago1.png\n","Found chicago2.png\n","Found chicago6.png\n","Found chicago4.png\n","Found chicago5.png\n","Found keanu2.png\n","Found keanu.png\n","Saved tpdne.png\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JYcbqB2NmKFm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":922},"outputId":"cb80b3dc-c909-4065-ea5b-7da757e9b4f3","executionInfo":{"status":"error","timestamp":1561491798417,"user_tz":240,"elapsed":40549,"user":{"displayName":"Alexandru Damian","photoUrl":"","userId":"02461557059013045939"}}},"source":["%cd /content/gdrive/My\\ Drive/stylegan-refactor\n","import logging\n","logging.getLogger('tensorflow').disabled = True\n","\n","import os\n","import sys\n","from pathlib import Path\n","from datetime import datetime\n","import glob\n","\n","file_path = Path().resolve()\n","print(\"Current Path: \" + str(file_path))\n","\n","last_edit,last_file = max([(os.stat(filename).st_mtime,filename) for filename in Path().glob('**/*.py')])\n","last_edit = datetime.fromtimestamp(last_edit)\n","current_time = datetime.now()\n","diff_time = current_time-last_edit\n","print(\"Last python file (\" + str(last_file) + \") was modified \" + str(diff_time.total_seconds())+\" seconds ago\")\n","\n","import argparse\n","import pickle\n","from tqdm import tqdm\n","import PIL.Image\n","import numpy as np\n","import dnnlib\n","import dnnlib.tflib as tflib\n","import config\n","from tensorflow.train import cosine_decay_restarts\n","from matplotlib import pyplot as plt\n","import scipy.misc\n","from SR.generator import Generator\n","from SR.optimizer import SROptimizer\n","from tqdm import trange\n","\n","URL_FFHQ = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ'  # karras2019stylegan-ffhq-1024x1024.pkl\n","\n","def get_args():\n","    parser = argparse.ArgumentParser(description='Style-Gan Super Resolution')\n","    parser.add_argument('-i', '--input_files', help='Input files')\n","    parser.add_argument('-o', '--output_dir', default=\"generated_images/\", help='Directory for storing output images and latents')\n","    parser.add_argument('-n', '--output_name', default=None, help='Name to call output file')\n","    parser.add_argument('--loss_dir', default=\"Loss/\", help='Directory for storing loss logs')\n","    parser.add_argument('--n_init', default=1, help='Number of initializations for encoder', type=int)\n","    parser.add_argument('--img_size', default=64, help='Size to rescale to', type=int)\n","    parser.add_argument('--loss', default='1.0*L2', help='Loss function to use')\n","    parser.add_argument('-LIN','--layersIN', default=[3,6,9], nargs='+',help='Which VGG-ImageNet layers to use',type=int)\n","    parser.add_argument('-LF','--layersF', default=[3,6,9], nargs='+',help='Which VGG-Face layers to use',type=int)\n","    parser.add_argument('--lr', default=1., help='Learning rate', type=float)\n","    parser.add_argument('--optimizer', default='SGD', help='Which optimizer to use')\n","    parser.add_argument('--cosine_cycle', default=None, help='Whether to use cosine annealing',type=int)\n","    parser.add_argument('--steps', default=1500, help='Number of gradient-descent steps', type=int)\n","    parser.add_argument('--mask_type', default=None, help='Whether to weight the pixels differently with a face mask')\n","\n","    args,other_args = parser.parse_known_args()\n","    if(len(other_args)>0): print(f\"Did not recognize arguments: {other_args}\")\n","    return args\n","\n","def plot_loss(losslist,best_losses,loss_dir):\n","    losses = np.array(losslist)\n","    axis = np.array(range(len(losses)))\n","    label = 'Loss'\n","    fig = plt.figure()\n","    plt.title(label)\n","    plt.plot(axis, losses, label=\"Loss\",zorder=1)\n","    plt.scatter(axis[best_losses], losses[best_losses], s=5, c='r', label=\"Best\",zorder=2)\n","    plt.legend()\n","    plt.xlabel('Steps')\n","    plt.ylabel('Loss')\n","    plt.grid(True)\n","    plt.savefig(loss_dir/'loss.pdf')\n","    plt.close(fig)\n","\n","sys.argv = [sys.argv[0],\n","              '-i', './aligned_realpics/chicago2.png',\n","              '-n', \"layer?.png\",\n","              '--img_size', '64', \n","              '--layersF', \"50\", \n","              '--loss', '1*FACE+0.04*REG+0.02*CROSS', \n","              '--lr', '0.1', \n","              '--steps', '50',\n","              '--optimizer', 'ADAM', \n","              '--mask_type', 'SEGMENT']\n","    \n","args = get_args()\n","\n","ref_images = Path().glob(args.input_files)\n","# ref_images = list(ref_images)\n","\n","output_dir = Path(args.output_dir)\n","output_dir.mkdir(exist_ok=True)\n","loss_dir = Path(args.loss_dir)\n","loss_dir.mkdir(exist_ok=True)\n","\n","# Load StyleGAN\n","print(\"Loading StyleGAN\")\n","tflib.init_tf()\n","with dnnlib.util.open_url(URL_FFHQ, cache_dir=config.cache_dir) as f:\n","    generator_network, discriminator_network, Gs_network = pickle.load(f)\n","\n","print(\"Loaded StyleGAN\")\n","\n","print(\"Creating Generator\")\n","G = Generator(Gs_network, args)\n","G.reset_latent()\n","print(\"Created Generator\")\n","print(\"Creating Optimizer\")\n","opt = SROptimizer(G, args)\n","print(\"Created Optimizer\")\n","\n","for i in range(1,18):\n","  args.output_name = f\"layer{i}.png\"\n","  opt.layersF = [i]\n","\n","  print(\"Building Loss\")\n","  opt.build_loss()\n","  print(\"Built Loss\")\n","\n","  losses=[]\n","  best_losses=[]\n","\n","  for image in ref_images:\n","      print(f\"Working on {image.name}\")\n","      opt.set_reference_image(image)\n","\n","      image_mask = opt.image_mask.eval()[0]\n","      image_mask = np.clip(255*image_mask,0,255).astype('uint8')\n","      image_mask = PIL.Image.fromarray(image_mask)\n","      image_mask.save(output_dir/'mask.png')\n","\n","      t = trange(args.steps)\n","\n","      min_loss = np.inf\n","      best_img = None\n","      best_idx = 0\n","      best_list = [np.inf,np.inf,np.inf]\n","      cos_iter = 0\n","      cos_cycle = args.cosine_cycle\n","\n","      for i in t:\n","          current_lr = args.lr\n","          if(cos_cycle is not None):\n","              current_lr = 1e-5 + 0.5 * (args.lr - 1e-5) * \\\n","               (1. + np.cos(cos_iter * np.pi / cos_cycle))\n","              cos_iter += 1\n","              if(cos_iter == cos_cycle):\n","                  cos_iter = 0\n","                  cos_cycle = 2*cos_cycle\n","          loss_list,loss = opt.step(lr=current_lr)\n","          losses.append(loss)\n","          curr_str = ' '.join([f\"{x[0]}: {x[1]:.3f}/{y:.3f}\" for x,y in zip(loss_list,best_list)])\n","          curr_str += f\", TOTAL: {loss:.3f}/{min_loss:.3f}, BEST_IDX: {best_idx}, LR: {current_lr:.5f}\"\n","\n","          if(loss < min_loss):\n","              min_loss = loss\n","              best_losses.append(i)\n","              best_idx = i\n","              best_list = [x[1] for x in loss_list]\n","              if(i>=0.1*args.steps):\n","                  generated_image = G.generate_images()\n","                  generated_latent = G.latent.eval()\n","                  best_img = PIL.Image.fromarray(generated_image[0], 'RGB')\n","                  best_latent=generated_latent\n","\n","          t.set_description(curr_str)\n","\n","          if(i%100 == 0):\n","              if(best_img is not None):\n","                  best_img.save(output_dir / image.name, 'PNG')\n","                  np.save(output_dir / image.stem, best_latent)\n","              plot_loss(losses,best_losses,loss_dir)\n","\n","      if(args.output_name is None):\n","          output_name = image.stem\n","      else:\n","          output_name = args.output_name\n","\n","      best_img.save(output_dir / f'{output_name}.png', 'PNG')\n","      np.save(output_dir / f'{output_name}.npy', best_latent)\n","      plot_loss(losses,best_losses,loss_dir)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/stylegan-refactor\n","Current Path: /content/gdrive/My Drive/stylegan-refactor\n","Last python file (SR/optimizer.py) was modified 1666.358866 seconds ago\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Loading StyleGAN\n","Loaded StyleGAN\n","Creating Generator\n","Created Generator\n","Creating Optimizer\n","Created Optimizer\n","Building Loss\n"," > Building FACE\n"," > > Using layers [1] for face loss\n"," > Building REG\n"," > Building CROSS\n","Built Loss\n","Working on chicago2.png\n","Built mask from image\n"],"name":"stdout"},{"output_type":"stream","text":["FACE: 0.542/0.568 REG: 2.598/2.640 CROSS: 10.476/10.761, TOTAL: 0.855/0.888, BEST_IDX: 47, LR: 0.10000: 100%|██████████| 50/50 [00:15<00:00,  5.01it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Building Loss\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-7f693d258a1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Building Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m   \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Built Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/My Drive/stylegan-refactor/SR/optimizer.py\u001b[0m in \u001b[0;36mbuild_loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_bicubic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerated_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image_mask'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mmasked_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerated_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1494\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1237\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m   def _get_partitioned_variable(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    560\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m   def _get_partitioned_variable(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    512\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     synchronization, aggregation, trainable = (\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"tensorflow/python\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" %\n\u001b[0;32m--> 864\u001b[0;31m                          (err_msg, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    865\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Variable image_mask already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/content/gdrive/My Drive/stylegan-refactor/SR/optimizer.py\", line 102, in build_loss\n    self.image_mask = tf.get_variable('image_mask',shape=(self.n_init,self.img_size,self.img_size,3))\n  File \"<ipython-input-1-7f693d258a1c>\", line 115, in <module>\n    opt.build_loss()\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n"]}]}]}