{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sr_alex.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"g5RQsvi5KYBM","colab_type":"code","outputId":"5e9dfcd2-6411-4937-b63d-a666723e4e9c","executionInfo":{"status":"ok","timestamp":1560368959720,"user_tz":240,"elapsed":23211,"user":{"displayName":"Alexandru Damian","photoUrl":"","userId":"02461557059013045939"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["  from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6udYoG1LKNS-","colab_type":"code","outputId":"b5180ccb-fbfc-45e7-b2ea-02117f3e5f47","executionInfo":{"status":"ok","timestamp":1560368961291,"user_tz":240,"elapsed":358,"user":{"displayName":"Alexandru Damian","photoUrl":"","userId":"02461557059013045939"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd gdrive/My\\ Drive/stylegan-encoder"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/stylegan-encoder\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cXKE7-YyseH6","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import scipy.stats\n","import numpy.linalg as la\n","import os\n","import argparse\n","import pickle\n","from tqdm import tqdm\n","import PIL.Image\n","import numpy as np\n","import dnnlib\n","import dnnlib.tflib as tflib\n","import config\n","from encoder.generator_model import Generator\n","from encoder.perceptual_model import PerceptualModel\n","import tensorflow as tf\n","import seaborn as sns"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D_mSXPUrqGbh","colab_type":"code","colab":{}},"source":["URL_FFHQ = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ'  # karras2019stylegan-ffhq-1024x1024.pkl\n","\n","def split_to_batches(l, n):\n","    for i in range(0, len(l), n):\n","        yield l[i:i + n]\n","\n","src_dir = \"./aligned_realpics/LR/\"\n","generated_images_dir = \"generated_images/\"\n","dlatent_dir = \"latent_representations/\"\n","image_size = 128\n","lr = 1\n","\n","ref_images = [os.path.join(src_dir, x) for x in os.listdir(src_dir)]\n","ref_images = list(filter(os.path.isfile, ref_images))\n","\n","if len(ref_images) == 0:\n","    raise Exception('%s is empty' % src_dir)\n","\n","os.makedirs(generated_images_dir, exist_ok=True)\n","os.makedirs(dlatent_dir, exist_ok=True)\n","\n","# Initialize generator and perceptual model\n","tflib.init_tf()\n","with dnnlib.util.open_url(URL_FFHQ, cache_dir=config.cache_dir) as f:\n","    generator_network, discriminator_network, Gs_network = pickle.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"otqKH7nRrSjt","colab_type":"code","colab":{}},"source":["rnd = np.random.RandomState(5)\n","mean_list = []\n","for i in range(5):\n","  print(i)\n","  latents = rnd.randn(100000, 512)\n","  out = Gs_network.components.mapping.get_output_for(latents, None)\n","  mean_latent = tf.reduce_mean(out,axis=0)\n","  mean_list.append(mean_latent[0].eval())\n","\n","latent_avg = np.mean(mean_list,axis=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XLUBMMP_EwcW","colab_type":"code","colab":{}},"source":["rnd = np.random.RandomState(5)\n","latents = rnd.randn(1000, 512)\n","out = Gs_network.components.mapping.get_output_for(latents, None)\n","out = out.eval()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bJSC9R0_CUF_","colab_type":"code","colab":{}},"source":["latent_avg = np.mean(mean_list,axis=0)\n","np.save(\"latent_avg.npy\",latent_avg)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bw57tetRrry1","colab_type":"code","colab":{}},"source":["dlatent = np.load('latent_representations/chicago2_01.npy')\n","plt.hist(dlatent.flatten(), bins=500, density=True);\n","print((np.sum(np.square(np.maximum(0,dlatent)))*0.25+np.sum(np.square(np.minimum(0,dlatent)))*4)/200)\n","print((np.sum(np.square(np.maximum(0,out)))*0.25+np.sum(np.square(np.minimum(0,out)))*4)/(200*1000))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oHSlAbDVoniy","colab_type":"code","colab":{}},"source":["generator = Generator(Gs_network, batch_size=1, randomize_noise=False)\n","\n","def generate_image(latent_vector):\n","    latent_vector = latent_vector.reshape((1, 18, 512))\n","    generator.set_dlatents(latent_vector)\n","    img_array = generator.generate_images()[0]\n","    img = PIL.Image.fromarray(img_array, 'RGB')\n","    return img.resize((512, 512))\n","  \n","def display_tensor(im):\n","    im=np.transpose(im,(1,2,0))\n","    im = (im+1)/2\n","    im = np.clip(im,0,1)\n","    plt.figure(figsize = (10,10))\n","    plt.imshow(im)\n","    plt.axis('off')\n","    \n","def gen_disp(latent_vector):\n","    latent_vector = latent_vector.reshape((1, 18, 512))\n","    img_array = Gs_network.components.synthesis.run(latent_vector)\n","    img_array = img_array[0]\n","    display_tensor(img_array)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MH751S8xWZ3_","colab_type":"code","colab":{}},"source":["def rescale(x,a,b):\n","  x[x < 0] *= a\n","  x[x >= 0] *= b\n","  \n","  return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qlAllQXHrz-m","colab_type":"code","colab":{}},"source":["mu=[]\n","sigma=[]\n","for i in range(512):\n","  a,b = scipy.stats.norm.fit(rescale(out[:,0,i].flatten(),1,1/5))\n","  mu.append(a)\n","  sigma.append(b)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IaqpfO9vcOSS","colab_type":"code","colab":{}},"source":["np.save(\"gaussian_fit.npy\",(mu,sigma))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dJdM0FRvTBaE","colab_type":"code","colab":{}},"source":["i=np.random.randint(0,512)\n","sns.distplot((out[:,0,i]-0.8*np.maximum(0,out[:,0,i])).flatten())\n","# sns.distplot(latents[:,i].flatten())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8khZxjk1Kbq_","colab_type":"code","colab":{}},"source":["latent_avg = np.load(\"latent_avg.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s0ikVYwJKbzO","colab_type":"code","colab":{}},"source":["sns.distplot(latent_avg)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jgc9LELRLYlS","colab_type":"code","colab":{}},"source":["gen_disp(np.repeat(np.repeat(latent_avg.mean(), 512, 0), 18, axis=0))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"msou0nkBLyeK","colab_type":"code","colab":{}},"source":["gen_disp(latent_avg)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2yKyJjJSKcXM","colab_type":"code","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J_0TeAk9V5nR","colab_type":"code","colab":{}},"source":["plt.imshow(np.cov(out[:,0,:].T))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XW6FkvSwT8gq","colab_type":"code","colab":{}},"source":["scale_out = np.maximum(0,out)/5+np.minimum(0,out)\n","import seaborn as sns\n","sns.distplot(scale_out.flatten(),fit=scipy.stats.norm,kde=False)\n","mu,sigma=scipy.stats.norm.fit(scale_out.flatten())\n","np.save(\"gaussian_fit.npy\",(mu,sigma))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JLMKEiRSDyJ7","colab_type":"code","colab":{}},"source":["mu,sigma=np.load(\"gaussian_fit.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fi9UwEFc168i","colab_type":"code","colab":{}},"source":["latents = rescale(rnd.randn(10000, 512)*sigma+mu,1,5)\n","# latents = np.repeat(latents, 18, axis=0)\n","sns.distplot(latents.flatten());"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rt5MLakU4H3G","colab_type":"code","colab":{}},"source":["rnd = np.random.RandomState(5)\n","latents = rnd.randn(1000, 512)\n","out_flat = Gs_network.components.mapping.get_output_for(latents, None)\n","out_flat=out_flat.eval()\n","out_flat = out_flat[:,0,:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8443zhHZ5Ouq","colab_type":"code","colab":{}},"source":["from sklearn.mixture import GaussianMixture\n","gmm = GaussianMixture(n_components=1).fit(out_flat)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yeqLqw1l5nxO","colab_type":"code","colab":{}},"source":["samples,_ = gmm.sample(1000);\n","sns.distplot(samples.flatten());"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E0crAdFp26Rj","colab_type":"code","colab":{}},"source":["mu,sigma = np.load(\"gaussian_fit.npy\")\n","latent_avg = np.load(\"latent_avg.npy\")\n","\n","rnd = np.random.RandomState(10)\n","z_latent = rnd.randn(1, 512)\n","latent_out = Gs_network.components.mapping.get_output_for(z_latent, None)\n","latent_out=latent_out.eval()\n","\n","latent_out[0:7,:] = latent_avg + (latent_out[0:7,:]-latent_avg)*0.7\n","\n","gen_disp(latent_out)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aSILLK_wLyll","colab_type":"code","colab":{}},"source":["mu,sigma = np.load(\"gaussian_fit.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F9esN9-OEPNv","colab_type":"code","colab":{}},"source":["# mu,sigma = np.load(\"gaussian_fit.npy\")\n","latent_avg = np.load(\"latent_avg.npy\")\n","\n","rnd = np.random.RandomState(120)\n","latents = rnd.randn(18, 512)*sigma+mu\n","# latents = np.repeat(latents, 18, axis=0)\n","\n","# latents[0:7,:] = mu + (latents[0:7,:] - mu)*0.7\n","\n","# latents = 2*mu-latents\n","\n","latents=rescale(latents,1,5)\n","\n","gen_disp(latents)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IJFNCSxRwFlK","colab_type":"code","outputId":"1307c1a9-69b0-47cc-abdd-08143fb73147","executionInfo":{"status":"ok","timestamp":1560371845294,"user_tz":240,"elapsed":19747,"user":{"displayName":"Alexandru Damian","photoUrl":"","userId":"02461557059013045939"}},"colab":{"base_uri":"https://localhost:8080/","height":802}},"source":["!python encode_images.py ./aligned_realpics/LR/ generated_images/ latent_representations/ --image_size 64 --lr 0"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","Current Path: /content/gdrive/My Drive/stylegan-encoder\n","Last python file (encoder/perceptual_model.py) was modified 55.63034 seconds ago\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1659, in _create_c_op\n","    c_op = c_api.TF_FinishOperation(op_desc)\n","tensorflow.python.framework.errors_impl.InvalidArgumentError: Dimensions must be equal, but are 1024 and 3 for 'BiasAdd' (op: 'BiasAdd') with input shapes: [1,64,64,1024], [3].\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"encode_images.py\", line 114, in <module>\n","    main()\n","  File \"encode_images.py\", line 69, in main\n","    perceptual_model.build_perceptual_model(generator.generator_output)\n","  File \"/content/gdrive/My Drive/stylegan-encoder/encoder/perceptual_model.py\", line 57, in build_perceptual_model\n","    preprocessed_generated_image = preprocess_input(tflib.convert_images_to_uint8(generated_image))\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/applications/__init__.py\", line 28, in wrapper\n","    return base_fun(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/applications/vgg16.py\", line 21, in preprocess_input\n","    return vgg16.preprocess_input(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras_applications/imagenet_utils.py\", line 195, in preprocess_input\n","    mode=mode, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras_applications/imagenet_utils.py\", line 149, in _preprocess_symbolic_input\n","    data_format=data_format)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 4080, in bias_add\n","    data_format='NHWC')\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\", line 1980, in bias_add\n","    return gen_nn_ops.bias_add(value, bias, data_format=data_format, name=name)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 745, in bias_add\n","    \"BiasAdd\", value=value, bias=bias, data_format=data_format, name=name)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n","    op_def=op_def)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n","    op_def=op_def)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1823, in __init__\n","    control_input_ops)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1662, in _create_c_op\n","    raise ValueError(str(e))\n","ValueError: Dimensions must be equal, but are 1024 and 3 for 'BiasAdd' (op: 'BiasAdd') with input shapes: [1,64,64,1024], [3].\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U1gC5xTYpnro","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}